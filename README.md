# SimGAN2
In July 2020, a number of researchers from Apple published the article "Learning from Simulated and Unsupervised Images through Adversarial Training". The article was created as a result of a broad problem in the field of deep learning. In order to train deep neural networks, many labeled datasets are required. However, labeling data sets is an expensive and time-consuming task. As a result, using a synthetic data set has become appealing because image labeling is done automatically. The problem that the article is trying to solve is that synthetic data is often not realistic enough, leading the deep neural network to learn details that exist in the synthetic images and not in reality. Using SimGAN architecture, that refines synthetic images from a simulator using neural network that calls ‘refiner network’, we enable Deep Learning models to take advantage of graphics engines which can produce enormous labeled datasets.
In this work we offer an improved version of the original SimGAN. By changing the self - regularization loss function of the refiner and fine tuning the hyper parameters, we were able to show a significant improvement over using synthetic images, and achieve state-of-the-art results on the MPIIGaze dataset without any labeled real data. We quantitatively evaluate the generated images by using metrics such as Fréchet Inception Distance (FID) and Mean Opinion Score (MOS).

Later in the study, we wanted to use a Siamese network instead of the L2 distance index in order to show an improvement in the results.
